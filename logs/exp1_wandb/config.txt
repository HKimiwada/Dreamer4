class TrainConfig:
    data_dir = Path("data")
    resize = (192, 320)
    patch_size = 16
    clip_length = 4
    batch_size = 1
    num_workers = 0
    input_dim = 3 * patch_size * patch_size
    embed_dim = 256
    latent_dim = 128
    num_heads = 8
    num_layers = 8
    lr = 1e-4
    weight_decay = 0.05
    max_epochs = 1
    log_interval = 5
    accumulation_steps = 8
    ckpt_dir = Path("checkpoints")
    alpha = 0.0
    project = "DreamerV4-tokenizer"
    entity = "hiroki-kimiwada-"     # stays as provided
    run_name = "v1_tokenizer_mse_only"

PYTHONPATH=. torchrun --nproc_per_node=2 training_script/train_tokenizer.py
num_workers=0
